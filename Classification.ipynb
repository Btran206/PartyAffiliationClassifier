{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Party Affiliation Based on Stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Finding out correlations between the stock trades that any representatives does, along with their party affiliation is an interesting task. It allows us to see if there are any possible relationships between the laws and bills that they pass and what stocks they invest in. If there is such a pattern, we want to be able to potentially identify what party that they would affiliate with to ensure that there isn't too much of one party being involved in pushing restrictions in order to further their earnings from their stock investments. In this project, we will attempt to predict the party affiliation of a representative through their stock trades, the amount of money that they involve in their stock trades, as well as several other features that were included in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'  # Higher resolution figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in dataframe from url\n",
    "url = 'https://house-stock-watcher-data.s3-us-west-2.amazonaws.com/data/all_transactions.json'\n",
    "all_transactions = requests.get(url).json() \n",
    "df = pd.DataFrame(all_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change missing values with np.nan\n",
    "df = df.replace('--', np.nan)\n",
    "df = df.fillna(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dates into datetime objects\n",
    "df['disclosure_date'] = pd.to_datetime(df['disclosure_date'])\n",
    "df['transaction_date'] = pd.to_datetime(df['transaction_date'], errors = 'coerce')\n",
    "#additionally, create a new column year so that we can identify stocks from 2018 above.\n",
    "df['transaction_year'] = df['transaction_date'].apply(lambda x: x.year)\n",
    "df = df[df['transaction_year'] >= 2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the ptr-link,asset_desc,owner\n",
    "df = df.drop(['ptr_link','asset_description','owner'],axis=1)\n",
    "representative = []\n",
    "#read in the representative's party from a text file.\n",
    "with open('representative_party.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    clean = []\n",
    "for i in lines:\n",
    "    if 'Transactions' in i or 'View' in i or 'photo' in i:\n",
    "        continue\n",
    "    clean.append(i)\n",
    "    representative_dict = {}\n",
    "for i in range(0, len(clean) - 1, 2):\n",
    "    representative_dict[clean[i].strip()] = clean[i + 1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a separate file for representatives, and merge it with the originial dataframe\n",
    "representatives = pd.DataFrame()\n",
    "representatives['representative'] = representative_dict.keys()\n",
    "representatives['party'] = representative_dict.values()\n",
    "df = df.merge(representatives, on = 'representative')\n",
    "#create a party column that represents the party of the representatives that are doing the trade\n",
    "df['party'] = df['party'].apply(lambda x: x.split()[0] if len(x.split()) == 3 else None)\n",
    "no_party = df[df['party'].isna()].index.to_list()\n",
    "df = df.drop(no_party)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Baseline Model\n",
    "For our baseline model, we first found the representative's parties through the representative summary from the website's html source (https://housestockwatcher.com/summary_by_rep) and scraped the values. We stored this into the text file representative_party. We also decided that out of the columns in the datasets, the ones that we wanted to include in our baseline model were the amount(ordinal), type(nominal) and cap_gains_over_200_usd(nominal). We believed that the ptr_link and asset_description were not necessary to include, as the ptr_link is matched with the representative variable, and the asset description is matched with the ticker. Additionally we chose not to include the owner column. For the encoding of the amount, we chose to ordinally encode them, as they were put into categories that represented the amount of money that was invested. For the type, we decided to use one hot encoding, as there is no order to the categories. Finally, we encoded the cap_gains_over_200_usd using binary encoding. After creating the pipeline, the accuracy for the model ranged from around 58 to 72 percent. We believe that our model scored on the low side, as 80% accuracy would have been more sufficient compared to something that was closer to a 50/50. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode amount column, since they are roughly categorical\n",
    "def label_conv(df):\n",
    "    keys = list(df['amount'].value_counts().index)\n",
    "    values = np.arange(0,len(keys))\n",
    "    conv= dict(zip(keys,values))\n",
    "    return df['amount'].transform(lambda x: conv.get(x)).to_numpy().reshape(-1,1)\n",
    "#convert the types into label encoding, decided to make exchange the same as sell\n",
    "def type_conv(df):\n",
    "    keys = list(df['type'].value_counts().index)\n",
    "    values = np.arange(0,len(keys))\n",
    "    conv= dict(zip(keys,values))\n",
    "    return df['type'].transform(lambda x: conv.get(x)).to_numpy().reshape(-1,1)\n",
    "#converts true into 1 and false into 0\n",
    "def cap_conv(df):\n",
    "    return df['cap_gains_over_200_usd'].transform(lambda x: 1 if x else 0).to_numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6696908602150538"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create the training and testing sets through train_test_split\n",
    "train_X,test_X,train_Y,test_Y = train_test_split(df[df.columns[:-1]],df.party)\n",
    "#Transformers that will be used in the columntransformer\n",
    "label_transformer = Pipeline([\n",
    "    ('label',FunctionTransformer(label_conv))\n",
    "])\n",
    "type_transformer = Pipeline([\n",
    "    ('type',FunctionTransformer(type_conv))\n",
    "])\n",
    "cap_transformer = Pipeline([\n",
    "    ('cap',FunctionTransformer(cap_conv))\n",
    "])\n",
    "preproc = ColumnTransformer(\n",
    "    transformers=[\n",
    "    ('s1',label_transformer,['amount']),\n",
    "    ('s2',type_transformer,['type']),\n",
    "    ('s3',cap_transformer,['cap_gains_over_200_usd']),\n",
    "])\n",
    "p2 = Pipeline(steps = [('preprecessor',preproc),('regressor',KNeighborsClassifier())])\n",
    "p2.fit(train_X,train_Y)\n",
    "p2.score(test_X,test_Y)\n",
    "#pretty low accuracy, want at least above 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model\n",
    "Our final model includes two engineered features utilizing the ticker and transaction_date columns. The transformation of tickers is based on a groupby statement on each ticker label and party and aggregating their counts. The reasoning I am doing this is to gather the proportions between each party and measuring the political lean for every single ticker. We grab every single ticker that has more than 60% favor towards a party, which is a threshold we found to be best after testing different numbers, and after doing so ordinal encode a number based on party affiliation. For the transactions_dates, we followed the same formula by finding the proportions of Democrats and Republicans that traded on each month. Our metric for choosing party affiliation is the absolute difference of the proportions and choosing a number that is above the 75th percentile which turns out to be any number greater than .00143951. After doing so we hard encoded the values visually for the months their party affiliations. For out model type we chose the KNN classifier because our features are primariliy ordinal meaning that KNN will make more accurate predictions based on distance. The paramaters that performed the best were the algorithm='brute', leaf_size=1, n_neighbors=13, p=2, weights='distance'using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the ticker column, we attempt to determine the party of an individual\n",
    "totals = df.groupby('ticker').count()\n",
    "tickers = totals.index.to_list()\n",
    "filtered = df[df.apply(lambda x: x['ticker'] in tickers, axis = 1)].groupby('ticker').count()['disclosure_year']\n",
    "democrat = df[df['party'] == 'Democrat']\n",
    "democrat = democrat[democrat.apply(lambda x: x['ticker'] in tickers, axis = 1)].groupby('ticker').count()\n",
    "republican = df[df['party'] == 'Republican']\n",
    "republican = republican[republican.apply(lambda x: x['ticker'] in tickers, axis = 1)].groupby('ticker').count()\n",
    "libertarian = df[df['party'] == 'Libertarian']\n",
    "libertarian = libertarian[libertarian.apply(lambda x: x['ticker'] in tickers, axis = 1)].groupby('ticker').count()\n",
    "ratio_D = democrat['disclosure_year'].divide(filtered)\n",
    "ratio_D = pd.DataFrame(ratio_D).rename(columns={\"disclosure_year\": \"Democrat\"})\n",
    "ratio_R = republican['disclosure_year'].divide(filtered)\n",
    "ratio_R = pd.DataFrame(ratio_R).rename(columns={\"disclosure_year\": \"Republican\"})\n",
    "ratio_L = libertarian['disclosure_year'].divide(filtered)\n",
    "ratio_L = pd.DataFrame(ratio_L).rename(columns={\"disclosure_year\": \"Libertarian\"})\n",
    "final = pd.concat([ratio_D, ratio_R, ratio_L], axis = 1)\n",
    "final = final[final.apply(lambda x: x > .6)]\n",
    "tickers = final.dropna(how = 'all')\n",
    "#This contains the Democrat's tickers\n",
    "democrat = tickers[['Democrat']].dropna().index.to_list()\n",
    "#This contains the Republican's tickers\n",
    "republican = tickers[['Republican']].dropna().index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.copy(deep = True)\n",
    "test['transaction_date'] = df['transaction_date'].apply(lambda x: x.month)\n",
    "x = test[['transaction_date', 'party', 'disclosure_year']].groupby(['transaction_date', 'party']).agg('count')\n",
    "x = x['disclosure_year']\n",
    "demo = []\n",
    "repub = []\n",
    "for i in range(len(x)//2):\n",
    "    demo.append(x.loc[(i+1, 'Democrat')] / 7504)\n",
    "    repub.append(x.loc[(i+1, 'Republican')] / 4394)\n",
    "ratios = pd.DataFrame({'democrat': demo, 'republican': repub})\n",
    "np.percentile(abs(ratios.diff(axis = 1)).republican, q = [.25, .5, .75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New features that we included, which \n",
    "def encode_ticker(df):\n",
    "    return df['ticker'].transform(lambda x: 1 if x in tickers else(2 if x in republican else 0)).to_numpy().reshape(-1,1)\n",
    "def encode_day(df):\n",
    "    return df['transaction_date'].dt.day.transform(lambda x: 0 if x in [3,5] else(1 if x==10 else 2)).to_numpy().reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8185483870967742"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X,test_X,train_Y,test_Y = train_test_split(df[df.columns[:-1]],df.party)\n",
    "#Final Pipeline, using KNN parameters that were given from the GridSearchCV\n",
    "knn=KNeighborsClassifier(algorithm='brute',\n",
    " leaf_size=1,\n",
    " n_neighbors=13,\n",
    " p=2,\n",
    " weights='distance')\n",
    "label_transformer = Pipeline([\n",
    "    ('label',FunctionTransformer(label_conv))\n",
    "])\n",
    "type_transformer = Pipeline([\n",
    "    ('type',FunctionTransformer(type_conv))\n",
    "])\n",
    "cap_transformer = Pipeline([\n",
    "    ('cap',FunctionTransformer(cap_conv))\n",
    "])\n",
    "ticker_transformer = Pipeline([\n",
    "    ('ticker',FunctionTransformer(encode_ticker))\n",
    "])\n",
    "day_transformer = Pipeline([\n",
    "    ('day',FunctionTransformer(encode_day))\n",
    "])\n",
    "preproc = ColumnTransformer(\n",
    "    transformers=[\n",
    "    ('s1',label_transformer,['amount']),\n",
    "    ('s2',type_transformer,['type']),\n",
    "    ('s3',cap_transformer,['cap_gains_over_200_usd']),\n",
    "     #additional feature 1\n",
    "    ('s4',ticker_transformer,['ticker']),\n",
    "    #additional feature 2\n",
    "    ('s5',day_transformer,['transaction_date']) \n",
    "])\n",
    "p3 = Pipeline(steps = [('preprecessor',preproc),('regressor',knn)])\n",
    "p3.fit(train_X,train_Y)\n",
    "p3.score(test_X,test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a deep copy of temp that has transformations applied so that we can run GridSearch\n",
    "x = df.copy(deep = True)\n",
    "temp = df.copy(deep=True)\n",
    "temp['amount'] = label_conv(temp)\n",
    "temp['type'] = type_conv(temp)\n",
    "temp['cap_gains_over_200_usd'] = cap_conv(temp)\n",
    "temp['ticker'] = encode_ticker(temp)\n",
    "temp['transaction_date'] = encode_day(temp)\n",
    "x = temp[['amount','type','cap_gains_over_200_usd','ticker','transaction_date']]\n",
    "y= df.party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y)\n",
    "knn = KNeighborsClassifier()\n",
    "param_grid = {\n",
    "    'n_neighbors' : list(range(1,30)),\n",
    "    'weights'     : ['uniform', 'distance'],\n",
    "    'algorithm'   : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'leaf_size'   : list(range(1,10)),\n",
    "    'p'           : [1,2]\n",
    "}\n",
    "# defining parameter range\n",
    "grid = GridSearchCV(knn, param_grid, cv=2, scoring='accuracy', return_train_score=False)\n",
    "grid_search=grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Evaluation\n",
    "For our fairness evaluation, we chose to test the keyword 'Hon.' in representative names. We wanted to check if our model predictions are fair for individuals that do not have Hon. in their names. For our parity measure we are going to choose true positive parity because our model should equally classify party affiliation of representatives with or without the Hon. title. After observing the recall_score of each category (Hon or 'no'Hon) the scores came out to be .72 for Hon and .99 for no Hon.. Which makes sense because after doing some EDA we found that almost every single representative that didn't have Hon in their names were Republican hence the very high recall score. To test whether our model predictions were not affected by this, we ran a permutation test on the recall score and found a pval of .01 which signifies that our model is not fair because it is biased for representatives that do not have Hon in their names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "yh_true = hon.party\n",
    "yn_true = no_hon.party\n",
    "p2.fit(hon[hon.columns[:-1]],hon.party)\n",
    "yh_pred = p2.predict(hon[hon.columns[:-1]])\n",
    "p2.fit(no_hon[no_hon.columns[:-1]],no_hon.party)\n",
    "yn_pred = p2.predict(no_hon[no_hon.columns[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7246401792639835"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(yh_true,yh_pred,labels=['Democrat','Republican'])\n",
    "# top row predicted,side row is actual\n",
    "recall_score(yh_true,yh_pred,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9966555183946488"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(yn_true,yn_pred,labels=['Democrat','Republican'])\n",
    "recall_score(yn_true,yn_pred,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "yh_pred = p3.predict(df[df.columns[:-1]])\n",
    "df['preds']=yh_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#permutation test\n",
    "df['Hon'] = df['representative'].apply(lambda x: True if 'Hon' in x else False)\n",
    "df['preds'] = df['preds'].apply(lambda x: 0 if x == 'Democrat' else 1)\n",
    "df['party'] = df['party'].apply(lambda x: 0 if x == 'Democrat' else 1)\n",
    "obs = df.groupby('Hon').apply(lambda x: recall_score(x.party, x.preds, average='micro')).diff().iloc[-1]\n",
    "metrs = []\n",
    "for _ in range(100):\n",
    "    s = (\n",
    "        df[['Hon', 'preds', 'party']]\n",
    "        .assign(Hon = df.Hon.sample(frac=1.0, replace=False).reset_index(drop=True))\n",
    "        .groupby('Hon')\n",
    "        .apply(lambda x: recall_score(x.party, x.preds, average='micro'))\n",
    "        .diff()\n",
    "        .iloc[-1]\n",
    "    )\n",
    "    metrs.append(s)\n",
    "pd.Series(metrs >= obs).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hon</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.765886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.826424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy\n",
       "Hon            \n",
       "False  0.765886\n",
       "True   0.826424"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( #getting the true accuracy of the representaives with/without hon being assigned a party\n",
    "    df\n",
    "    .groupby('Hon')\n",
    "    .apply(lambda x: recall_score(x.party, x.preds, average='micro'))\n",
    "    .rename('accuracy')\n",
    "    .to_frame()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
